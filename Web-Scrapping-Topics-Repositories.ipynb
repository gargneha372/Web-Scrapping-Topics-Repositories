{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb126db",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories for Topics on GitHub\n",
    "##### Web Scrapping : \n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "#### GitHub :\n",
    "GitHub is a code hosting platform for version control and collaboration. It lets you and others work together on projects from anywhere.\n",
    "#### Tools used :\n",
    "Python, requests, Beautiful Soup, Pandas, OS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8767a2",
   "metadata": {},
   "source": [
    "# Steps that are followed\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the top 25 repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "\n",
    "Repo Name,Username,Stars,Repo URL\n",
    "\n",
    "three.js,mrdoob,88300,https://github.com/mrdoob/three.js"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a59414",
   "metadata": {},
   "source": [
    "## Scrapping the list of topics from GitHub\n",
    "1. Use requests to downlaod the page\n",
    "2. Use BS4 to parse and extract information\n",
    "3. Convert to a Pandas dataframe\n",
    "\n",
    "Writing a function to download the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c5ddcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_topics_page():\n",
    "    # TODO - add comments\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "543f6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the \"Doc\" for GitHub topic page \n",
    "doc= get_topics_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6770db06",
   "metadata": {},
   "source": [
    "##### Creating some other helper functions to get information from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b43094c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags= doc.find_all('p', {'class' : selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88ef94",
   "metadata": {},
   "source": [
    "#### get_topic_titles can be used to get list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96524c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "096e10d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e3b41c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0a2f3",
   "metadata": {},
   "source": [
    "##### Similary functions have been defined for description and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7768800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the desc of each Topic\n",
    "def get_topic_descs(doc):\n",
    "    desc_selector = \"f5 color-fg-muted mb-0 mt-1\"\n",
    "    topic_desc_tags = doc.find_all('p', {'class' :desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00a2727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc= get_topic_descs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "793e8524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D modeling is the process of virtually developing the surface and structure of a 3D object.',\n",
       " 'Ajax is a technique for creating interactive web applications.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0d45bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the URL of each Topic\n",
    "def get_topic_urls(doc):\n",
    "    topic_link_tags= doc.find_all('a',{'class' :\"no-underline flex-grow-0\"})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9524b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d', 'https://github.com/topics/ajax']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_urls(doc)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27160b56",
   "metadata": {},
   "source": [
    "#### Puting all together into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75bf45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87bfda9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D modeling is the process of virtually develo...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D modeling is the process of virtually develo...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_topics().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94eb6b2",
   "metadata": {},
   "source": [
    "# Get the top 20 repositories from a topic page\n",
    "1. Use requests to downlaod the page and extract the information by using BS4\n",
    "2. Convert it to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6dc4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # Parse using Beautiful soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65482fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc = get_topic_page('https://github.com/topics/3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7663fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars):\n",
    "    stars=stars.strip()\n",
    "    if stars[-1]=='k':\n",
    "        return int(float(stars[:-1])*1000)\n",
    "    return(int(stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8cba9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h3_tag, star_tag):\n",
    "    # returns all the required info about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    base_url= \"https://github.com\"\n",
    "    repo_url =  base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "351cafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h1 tags containing repo title, repo URL and username\n",
    "    h3_selection_class = \"f3 color-fg-muted text-normal lh-condensed\"  \n",
    "    repo_tags = topic_doc.find_all('h3', {'class': h3_selection_class})\n",
    "    # Get star tags\n",
    "    star_tags= topic_doc.find_all('span', {'class' :'Counter js-social-count'})\n",
    "    \n",
    "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
    "\n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6d2cc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>repo_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrdoob</td>\n",
       "      <td>three.js</td>\n",
       "      <td>88300</td>\n",
       "      <td>https://github.com/mrdoob/three.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pmndrs</td>\n",
       "      <td>react-three-fiber</td>\n",
       "      <td>21000</td>\n",
       "      <td>https://github.com/pmndrs/react-three-fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>libgdx</td>\n",
       "      <td>libgdx</td>\n",
       "      <td>21000</td>\n",
       "      <td>https://github.com/libgdx/libgdx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BabylonJS</td>\n",
       "      <td>Babylon.js</td>\n",
       "      <td>19200</td>\n",
       "      <td>https://github.com/BabylonJS/Babylon.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssloy</td>\n",
       "      <td>tinyrenderer</td>\n",
       "      <td>15800</td>\n",
       "      <td>https://github.com/ssloy/tinyrenderer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username          repo_name  stars  \\\n",
       "0     mrdoob           three.js  88300   \n",
       "1     pmndrs  react-three-fiber  21000   \n",
       "2     libgdx             libgdx  21000   \n",
       "3  BabylonJS         Babylon.js  19200   \n",
       "4      ssloy       tinyrenderer  15800   \n",
       "\n",
       "                                      repo_url  \n",
       "0           https://github.com/mrdoob/three.js  \n",
       "1  https://github.com/pmndrs/react-three-fiber  \n",
       "2             https://github.com/libgdx/libgdx  \n",
       "3      https://github.com/BabylonJS/Babylon.js  \n",
       "4        https://github.com/ssloy/tinyrenderer  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_repos(topic_doc).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c122680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa58333",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "1. We have a funciton to get the list of topics\n",
    "2. We have a function to create a CSV file for scraped repos from a topics page\n",
    "3. Let's create a function to put them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b6731276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    \n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fdcd3d",
   "metadata": {},
   "source": [
    "#### Let's run it to scrape the top repos for the all the topics on the first page of https://github.com/topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5839265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "The file data/3D.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Ajax\"\n",
      "The file data/Ajax.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "The file data/Algorithm.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Amp\"\n",
      "The file data/Amp.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Android\"\n",
      "The file data/Android.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Angular\"\n",
      "The file data/Angular.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Ansible\"\n",
      "The file data/Ansible.csv already exists. Skipping...\n",
      "Scraping top repositories for \"API\"\n",
      "The file data/API.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Arduino\"\n",
      "The file data/Arduino.csv already exists. Skipping...\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "The file data/ASP.NET.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Atom\"\n",
      "The file data/Atom.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "The file data/Awesome Lists.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "The file data/Amazon Web Services.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Azure\"\n",
      "The file data/Azure.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Babel\"\n",
      "The file data/Babel.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Bash\"\n",
      "The file data/Bash.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "The file data/Bitcoin.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "The file data/Bootstrap.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Bot\"\n",
      "The file data/Bot.csv already exists. Skipping...\n",
      "Scraping top repositories for \"C\"\n",
      "The file data/C.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Chrome\"\n",
      "The file data/Chrome.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "The file data/Chrome extension.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Command line interface\"\n",
      "The file data/Command line interface.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Clojure\"\n",
      "The file data/Clojure.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Code quality\"\n",
      "The file data/Code quality.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Code review\"\n",
      "The file data/Code review.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Compiler\"\n",
      "The file data/Compiler.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "The file data/Continuous integration.csv already exists. Skipping...\n",
      "Scraping top repositories for \"COVID-19\"\n",
      "The file data/COVID-19.csv already exists. Skipping...\n",
      "Scraping top repositories for \"C++\"\n",
      "The file data/C++.csv already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d5006",
   "metadata": {},
   "source": [
    "#### We can check CSVs were created properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7e0a6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We have scrapped the data for top repositories for each topic occured on 1st page.\n",
    "- We have created a folder which includes all the csv files of each topic having information about repositories.\n",
    "- Repository information covers - username, repo_name, stars & repo_url."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49af92",
   "metadata": {},
   "source": [
    "## Ideas for future work\n",
    "- We can iterate through multipages by just being limited to 1st page and get the required data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
